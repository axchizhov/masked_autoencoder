# Эксперименты с автоэнкодером

## Идея

При выборе архитектуры для автоэнкодера я хотел получить:

* хорошую точность на выходе
* не слишком сложную архитектуру для простоты реализации и поддержки
* модель, не слишком требовательную к вычислительным ресурсам на этапе обучения

Для этого я выборочно просмотрел ряд State of the art решений за последние пару лет:

[![Papers with code leaderboard](/assets/leaderboard.png 'Leaderboard')](https://paperswithcode.com/sota/self-supervised-image-classification-on)

В итоге остановился на идеи из статьи [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377).

Архитектура основа на трансформерах, выглядит так:
![Архитектура](assets/mae_arch.png)

Идея в том, чтобы на этапе обучения подавать на вход модели только несколько фрагментов изображения для борьбы с переобучением. Кроме экономии на энокдинге изображения (выбрасывается порядка ~75% изображения), снижается и потребность в аугументациях.

Выглядит это так:
![Alt text](assets/example_results.png)

## Параметры архитектуры и обучение

На вход модели подавал 32х32 изображения из Cifar10, никаких аугументаций не делал.

Размерность скрытого представления выбрал emb_dim=192. У авторов архитектуры оно побольше, но они тестировались на ImageNet-1K, там в 100 раз больше данных и разрешение тоже больше. Для исключения переобучения сразу поставил скрытое представление небольшим.

Автоэнкодер обучал 11 часов на Nvidia T4, 300 эпох.

На валидационном датасете ...

Ради экономии времнии, качество автоэнкодера оценивал максимально просто

визуально + точность

скрин тензорборда

## Классификация на скрытом представлении

Модель простейшая ...

качество классификатора на 


## Выводы и идеи

Прогонка автоэнкодера на валидационном и тестовом датасетах. 
Тщательный выбор гиперпараметров


## Репликация результатов

```
python3.10 -m pip install torch torchvision notebook ipywidgets torchinfo pytest matplotlib tensorboard tqdm timm

python -m pip install -e .
``````



Что осталось за кадром?

